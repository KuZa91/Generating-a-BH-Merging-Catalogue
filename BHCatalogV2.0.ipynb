{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> BBHs merging catalog generator V2.0</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we'll implement a notebook that, given a certain volume of sky, will return a catalog of possible BBHs merging events.\n",
    "The probability distribution implemented for the variables of the events, will be taken from [B. P. Abbott T1](https://arxiv.org/abs/1811.12940), [B. P. Abbott T2](https://arxiv.org/abs/2010.14533).\n",
    "First of all, we need to import some modules ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sc\n",
    "import statistics as st\n",
    "import random\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool, Manager, Value\n",
    "from functools import partial\n",
    "from LISAhdf5 import LISAhdf5,ParsUnits\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Mass distribution functions </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining the probability distribution in function of the masses.\n",
    "\n",
    "We have :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model B mass distribution function of the paper arxiv 1811.12940\n",
    "\n",
    "# Mass Distribution parameters (values taken from the results of arxiv 1811.12940)\n",
    "\n",
    "#m_min = 5. # Solar Masses\n",
    "#m_max = 50. # Solar Masses\n",
    "#alpha = 1.6 # +-1.6 Big Error !\n",
    "#beta_q = 6.7 # +4.8 -5.9 Still Big Error !\n",
    "\n",
    "# Function for estimating the Phase Space costant of the Mass distribution\n",
    "\n",
    "#def ModBPS(ran_m1, ran_m2, m_min, m_max, alpha, beta_q):\n",
    "#    \n",
    "#    ris = 0.\n",
    "#    \n",
    "#    for i in range(len(ran_m1)- 1):\n",
    "#        for j in range(len(ran_m2)- 1):\n",
    "#            if(ran_m1[i] >= m_min and ran_m1[i] <= m_max and ran_m2[j] <= ran_m1[i] and ran_m2[j] >= m_min):\n",
    "#                mid_m1 = 0.5*(ran_m1[i + 1] + ran_m1[i])\n",
    "#                mid_m2 = 0.5*(ran_m2[j + 1] + ran_m2[j])\n",
    "#                q = mid_m2/mid_m1 \n",
    "#                ris +=  (ran_m1[i + 1] - ran_m1[i])*(ran_m2[j + 1] - ran_m2[j])*(np.power(mid_m1, (-alpha))*np.power(q, beta_q))\n",
    "#   \n",
    "#    return ris\n",
    "\n",
    "# Function for the distribution in function of mass (as used in paper arxiv 1811.12940)\n",
    "\n",
    "#def MassDistr(m1, m2, m_min, m_max, alpha, beta_q, C_norm):\n",
    "#    if(m1 >= m_min and m1 <= m_max and m2 <= m1 and m2 >= m_min) :\n",
    "#        q = m2/m1\n",
    "#        return (C_norm*np.power(m1, (-alpha))*np.power(q, beta_q))\n",
    "#    else :\n",
    "#        return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power law + Peak Mass Model of the paper arxiv 2010.14533\n",
    "\n",
    "# Mass Distribution parameters (values taken from the results of arxiv 2010.14533)\n",
    "\n",
    "m_min = 5. # Solar Masses (in the paper 4.53 + 1.47 - 1.89 Solar Masses)\n",
    "m_max = 100. # Solar Masses (in the paper 86.73 + 11.56 - 12.37 Solar Masses)\n",
    "alpha = 2.62 # +0.73 - 0.62\n",
    "beta_q = 1.26 # +2.37 -1.62 \n",
    "delta_m = 4.88 # + 4.10 -4.25 Solar Masses \n",
    "lambda_peak = 0.10 # +0.14 -0.07 \n",
    "mu_m = 33.49 # +4.54 -5.51 Solar Masses\n",
    "sigma_m = 5.09 # +4.28 - 4.34 Solar Masses\n",
    "\n",
    "# Defining of the smoothing function for m close to the minimimum mass\n",
    "\n",
    "def MassSmoothing(m, m_min, delta_m):\n",
    "    if(m < m_min):\n",
    "        return 0.\n",
    "    else:\n",
    "        if(m >= (m_min + delta_m)):\n",
    "            return 1.\n",
    "        else:\n",
    "            factor = np.exp((delta_m/(m - m_min)) + (delta_m/(m - m_min - delta_m)))\n",
    "            return 1./(factor + 1.)\n",
    "\n",
    "# Defining a normalized power law distribution function, needed for the final distribution function        \n",
    "        \n",
    "def MassPowLaw(m, m_min, m_max, alpha, PL_norm):\n",
    "    if(m_min < m < m_max):\n",
    "        return (1./PL_norm)*(m**(-alpha))\n",
    "    else:\n",
    "        return 0.\n",
    "    \n",
    "# Estimating the Phase space of the Power law distribution using trapezoidal integration\n",
    "    \n",
    "def PowerLawPS(ran_m1, m_min, m_max, alpha):\n",
    "    \n",
    "    ris = 0.\n",
    "    \n",
    "    for i in range(len(ran_m1)- 1):\n",
    "       if(ran_m1[i] >= m_min and ran_m1[i] <= m_max):\n",
    "                mid_m1 = 0.5*(ran_m1[i + 1] + ran_m1[i])\n",
    "                ris +=  (ran_m1[i + 1] - ran_m1[i])*(np.power(mid_m1, (-alpha)))\n",
    "   \n",
    "    return ris\n",
    "\n",
    "    \n",
    "# Defining a Gaussian distribution of the mass, needed for the final distribution function\n",
    "\n",
    "def MassGauss(m, mu_m, sigma_m, GS_norm):\n",
    "    return ((1./(sigma_m*np.sqrt(2.*np.pi)))*np.exp(-0.5*((m-mu_m)/sigma_m)**2.))*1./GS_norm\n",
    "\n",
    "def GaussPS(ran_m1, m_min, m_max, mu_m, sigma_m):\n",
    "    \n",
    "    ris = 0.\n",
    "    \n",
    "    for i in range(len(ran_m1)- 1):\n",
    "       if(ran_m1[i] >= m_min and ran_m1[i] <= m_max):\n",
    "                mid_m1 = 0.5*(ran_m1[i + 1] + ran_m1[i])\n",
    "                ris +=  (ran_m1[i + 1] - ran_m1[i])*((1./(sigma_m*np.sqrt(2.*np.pi)))*np.exp(-0.5*((mid_m1-mu_m)/sigma_m)**2.))\n",
    "   \n",
    "    return ris\n",
    "\n",
    "\n",
    "# Defining the proper Mass distribution function\n",
    "\n",
    "def MassDistr(m1, m2, m_min, m_max, alpha, beta_q, delta_m, lambda_peak, mu_m, sigma_m, PL_norm, GS_norm, Mass_PS):\n",
    "    \n",
    "    if(m1 > m2):\n",
    "        return ((1. - lambda_peak)*MassPowLaw(m1, m_min, m_max, alpha, PL_norm) + \\\n",
    "                lambda_peak*MassGauss(m1, mu_m, sigma_m, GS_norm))*MassSmoothing(m1, m_min, delta_m)*\\\n",
    "                ((m2/m1)**(beta_q))*MassSmoothing(m2, m_min, delta_m)*(1./Mass_PS)\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "# Estimating the Phase space for the Model C Mass distribution function using trapezoidal integration\n",
    "\n",
    "def ModCPS(ran_m1, ran_m2, m_min, m_max, alpha, beta_q, delta_m, lambda_peak, mu_m, sigma_m, PL_norm, GS_norm, Mass_PS):\n",
    "    \n",
    "    ris = 0.\n",
    "    \n",
    "    for i in range(len(ran_m1)- 1):\n",
    "        for j in range(len(ran_m2)- 1):\n",
    "             if(ran_m1[i] >= ran_m2[j]):\n",
    "                mid_m1 = 0.5*(ran_m1[i + 1] + ran_m1[i])\n",
    "                mid_m2 = 0.5*(ran_m2[j + 1] + ran_m2[j])\n",
    "                q = mid_m2/mid_m1 \n",
    "                ris +=  (ran_m1[i + 1] - ran_m1[i])*(ran_m2[j + 1] - ran_m2[j])*((1. - lambda_peak)\\\n",
    "                *MassPowLaw(mid_m1, m_min, m_max, alpha, PL_norm) + lambda_peak*MassGauss(mid_m1, mu_m, sigma_m, GS_norm))\\\n",
    "                *MassSmoothing(mid_m1, m_min, delta_m)*(q**(beta_q))*MassSmoothing(mid_m2, m_min, delta_m)\\\n",
    "                *(1./Mass_PS)\n",
    "   \n",
    "    return ris\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we will also need a function that return the Chirp Mass, given the mass of the two events involved in the binary merging :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that return the Chirp Mass of a binary merging event\n",
    "\n",
    "def ChirpMass(m1,m2): \n",
    "   return ((m1*m2)**(3./5.))/((m1+m2)**(1./5.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Redshift dependent statistic </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we'll need a function that allow us to convert from redshift to Gigaparsec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a function to convert from Z to GPC using Hubble Law\n",
    "\n",
    "def Z_to_Gpc(z):\n",
    "    return ((z*c*(10**(-3)))/(H_0)) # only valid for z < 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the function that estimates the differential comoving volume in function of the redshift :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the following function, the differential comoving volume in function of the redshift will be estimated as a spherical surface, it need to be integrated over dr to obtain the real volume \n",
    "\n",
    "def DeVC(z):\n",
    "    r = Z_to_Gpc(z)    \n",
    "    return ((4.*c*(10**(-3))*np.pi*(r**2.))/(H_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may now define, the merging rate as a function of the redshift _z_ as :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant merging rate throughout the volume as fitted in the paper arxiv 1811.12940\n",
    "\n",
    "#def R(z):\n",
    "#    return 53.2 # +58.5 - 27.0 Gpc^-3 yr-1 Merger rate density assumed constant over the comoving volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the merging rate as described in the paper arxiv 2010.14533, the flag Red_evol will decide if adopting a merging rate the evolve with redshift (true) or not (false)\n",
    "\n",
    "def R(z):\n",
    "    if(Red_evol):\n",
    "        R_0 = 19.1 # +16.2 - 9.0 GPc^-3 yr⁻1\n",
    "        k = 1.3 # +2.1 - 2.1 VALID FOR POWER LAW + PEAK MODEL MASS DISTRIBUTION\n",
    "        return R_0*(1+z)**(k)\n",
    "    else:\n",
    "        R_0 = 23.9 # +14.9 - 8.6 GPc^-3 yr^-1 Middle value fitted using a Power Law + Peak mass model and a non evolving merging rate\n",
    "        return R_0        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Spin distribution functions </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the spin distribution function as a Beta function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spin Amplitude Distribution parameter (values taken from the paper arxiv 2010.14533)\n",
    "\n",
    "Expected_a = 0.25 # +0.09 - 0.07\n",
    "Var_a = 0.03  # +0.02 - 0.01\n",
    "a_max = 1.\n",
    "\n",
    "\n",
    "def BetaSpinParameters(Expected_a, Var_a):\n",
    "    expec_rel = (Expected_a/(1. - Expected_a))\n",
    "    beta_a = ((expec_rel - Var_a*np.power(1. + expec_rel, 2.))/(Var_a*np.power(1. + expec_rel, 3.)))\n",
    "    alpha_a = expec_rel*beta_a\n",
    "    return alpha_a, beta_a\n",
    "\n",
    "alpha_a, beta_a = BetaSpinParameters(Expected_a, Var_a)\n",
    "\n",
    "if(alpha_a <=1 or beta_a <=1):\n",
    "    print('Error in the selection of the values for E[a] and Var[a]')\n",
    "\n",
    "# Estimating the beta function, that will be used as a normalization constant, by using the trapeze method to avoid problems in the extremes\n",
    "\n",
    "def Beta_Func(span_a, alpha_a, beta_a):\n",
    "    ris = 0.\n",
    "    for i in range(len(span_a)- 1):\n",
    "        mid_a = 0.5*(span_a[i + 1] + span_a[i])\n",
    "        ris +=  (span_a[i + 1] - span_a[i])*(np.power(mid_a,(alpha_a - 1.))*np.power((1. - mid_a),(beta_a - 1.)))\n",
    "   \n",
    "    return ris\n",
    "\n",
    "# Distribution for the spin amplitude, the beta distribution could get values bigger than 1 !\n",
    "\n",
    "def SpinModDistrib(a, alpha_a, beta_a, Beta_Val):\n",
    "     \n",
    "    return ((np.power(a, alpha_a - 1.)*np.power(1. - a, beta_a - 1.))/(Beta_Val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while the spin orientations distribution is given by :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spin tilt Distribution parameters (values assumed considering the results of arxiv 2010.14533)\n",
    "\n",
    "sigma_1 = 0.80 # + 1.08 - 0.45\n",
    "sigma_2 = 0.80 # + 1.08 - 0.45\n",
    "zeta = 0.76 # + 0.22 - 0.45\n",
    "\n",
    "# Spin orientation distribution, zeta = 1 gives a gaussian distribution centered in cos_ti = 1, zeta = 0 will return a isotropic distribution\n",
    "\n",
    "def SpinOrientDistrib(cos_t1,cos_t2, zeta, sigma_1, sigma_2):\n",
    "    prob = (1. - zeta)/(4) + ((2.*zeta)/(np.pi))*\\\n",
    "    (np.exp(-((np.power(1. - cos_t1,2.))/(2.*np.power(sigma_1,2.))))/(sigma_1*sc.erf(np.sqrt(2)/sigma_1)))\\\n",
    "    *(np.exp(-((np.power(1. - cos_t2,2.))/(2.*np.power(sigma_2,2.))))/(sigma_2*sc.erf(np.sqrt(2)/sigma_2)))\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Number of events in function of the parameters </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may finally define the distribution function for the number of events :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density function for the events in function of the parameters\n",
    "\n",
    "def NDistrib(z,m1,m2,a_1,a_2,cos_t1,cos_t2):\n",
    "    n = R(z)*DeVC(z)*(T_tot /(1. + z)) \\\n",
    "    *MassDistr(m1, m2, m_min, m_max, alpha, beta_q, delta_m, lambda_peak, mu_m, sigma_m, PL_norm, GS_norm, Mass_PS) \\\n",
    "    *SpinModDistrib(a_1, alpha_a, beta_a, BetaVal)*SpinModDistrib(a_2, alpha_a, beta_a, BetaVal) \\\n",
    "    *SpinOrientDistrib(cos_t1, cos_t2, zeta, sigma_1, sigma_2)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Frequency of the generated events </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we implement a function to roughly estimate the initial orbital frequency of the event given the massess and the residual coalescence time, as taken by **equation 11 a)** of [S. Marsat and J. G. Baker](https://arxiv.org/pdf/1806.10734.pdf); from that equation we may also estimate the residual time for the events frequency to go outside of the LISA band :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function given the mass of the two events and the residual time to coalescence, return the initial frequency of the event at the LISA detection time\n",
    "def GetInitialFrequency(m1,m2,coal_T):\n",
    "    M = m1 + m2\n",
    "    ni = (m1*m2)/(M*M)\n",
    "    res = ((256.*ni)/(5.*np.power((c*(10.**3.)),5.)))*np.power((G*M*sol_mass),(5./3.))*coal_T\n",
    "    return (np.power(res,(-(3./8.)))/np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function given the mass of the two events and the max frequency detectable, return the residual time that the event will spend on the Lisa band\n",
    "def TimeOutFrqRange(m1,m2,f_max):\n",
    "    M = m1 + m2\n",
    "    ni = (m1*m2)/(M*M)\n",
    "    res = (5.*np.power((c*(10.**3.)),5.))/(256.*ni*np.power((np.pi*f_max),(8./3.))*np.power((G*M*sol_mass),(5./3.)))\n",
    "    return res/year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Functions for the generation of the catalogue </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining a function that randomly generate a name for the single events, just to make the result appear sexier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will generate a fake name for the event in the time range of the LISA mission, it will not generate events in the day 29,30,31\n",
    "\n",
    "def Gen_Event_name():\n",
    "    \n",
    "    month = random.randrange(12) + 1\n",
    "    day = random.randrange(28) + 1\n",
    "    nid = str(random.randrange(1000) + 1)\n",
    "    \n",
    "    if month < 10 :\n",
    "        month = '0'+ str(month)        \n",
    "    else:\n",
    "        month = str(month)\n",
    "        \n",
    "    if day < 10 :\n",
    "        day = '0'+ str(day)        \n",
    "    else:\n",
    "        day = str(day)    \n",
    "        \n",
    "    return \"GW\"+ str(random.randrange(34,37))+ month + day +\"NId\"+ nid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may hence define a function that will give a uniform random value in the considered bin, this function will smoothen up the values of the generated catalogue in order to not have a single representant parameter for each of the considered bin :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a number of events equal to the lenght of the array N_EvXBin, with random values in the phase deltavolume for each of the parameter\n",
    "\n",
    "def Gen_Events_Parameters(idx_m1, idx_m2, idx_z, idx_a1, idx_a2, idx_ct1, idx_ct2) :\n",
    "                                \n",
    "        ev_m1 = random.uniform(ran_m1[idx_m1],ran_m1[idx_m1 + 1])\n",
    "        ev_m2 = random.uniform(ran_m2[idx_m2],ran_m2[idx_m2 + 1])\n",
    "        ev_z = random.uniform(ran_z[idx_z],ran_z[idx_z + 1])\n",
    "        \n",
    "        # If SNR Cut implemented, checking if the event SNR is bigger than the treshold, if not just generating the events\n",
    "        \n",
    "        if((not SNR_Cut) or (SNR_Cut and (ChirpMass(ev_m1, ev_m2) >SNR_Cutoff(ev_z)))):\n",
    "        \n",
    "            # By convention we impose that m1 is the biggest mass among the 2\n",
    "            if(ev_m2 > ev_m1):\n",
    "                app = ev_m1\n",
    "                ev_m1 = ev_m2\n",
    "                ev_m2 = app\n",
    "            ev_ttilde = random.uniform(0., max_tc)                            \n",
    "            ev_ifrq = GetInitialFrequency(ev_m1,ev_m2,ev_ttilde*year)\n",
    "        \n",
    "            # If the event frequency is within the LISA band the others parameters would be generated, in the other case the event is rejected \n",
    "        \n",
    "            if(ev_ifrq <= frq_max):\n",
    "                ev_ttmaxfr = ev_ttilde -TimeOutFrqRange(ev_m1, ev_m2, frq_max)\n",
    "            \n",
    "            \n",
    "                #ev_nm = Gen_Event_name()\n",
    "            \n",
    "                ev_sa1 = random.uniform(ran_a_1[idx_a1],ran_a_1[idx_a1 + 1])\n",
    "                ev_sa2 = random.uniform(ran_a_2[idx_a2],ran_a_2[idx_a2 + 1])\n",
    "            \n",
    "                # As we imposed the simmetry of the spin amplitude distribution, and we run the simulation over sa1 > sa2 by doubling the generated events, let's give a chance to invert the spin among the 2 \n",
    "            \n",
    "                if(np.random.random() >= 0.5):\n",
    "                    app = ev_sa1\n",
    "                    ev_sa1 = ev_sa2\n",
    "                    ev_sa2 = app\n",
    "            \n",
    "                ev_st1 = np.arccos(random.uniform(ran_cos_t1[idx_ct1],ran_cos_t1[idx_ct1 + 1]))\n",
    "                ev_st2 = np.arccos(random.uniform(ran_cos_t2[idx_ct2],ran_cos_t2[idx_ct2 + 1]))\n",
    "            \n",
    "                # As we imposed the simmetry of the spin tilt distribution, and we run the simulation over st1 > st2 by doubling the generated events, let's give a chance to invert the tilt among the 2 \n",
    "            \n",
    "                if(np.random.random() >= 0.5):\n",
    "                    app = ev_st1\n",
    "                    ev_st1 = ev_st2\n",
    "                    ev_st2 = app\n",
    "            \n",
    "                # Appending the generated event to the catalogue\n",
    "            \n",
    "                BH = pd.DataFrame([[ev_z, ev_m1, ev_m2, ev_ifrq, ev_ttmaxfr, ev_ttilde, ev_sa1, ev_sa2, ev_st1, ev_st2],],\\\n",
    "                                columns = ['Redshift', 'Mass1', 'Mass2', 'InitialFrequency', 'InBandTime',  'CoalTime', 'Spin1', 'Spin2', 'AzimuthalAngleOfSpin1', 'AzimuthalAngleOfSpin2'])\n",
    "                return BH\n",
    "            else:\n",
    "                BH = pd.DataFrame({'none' : []})\n",
    "                return BH\n",
    "            \n",
    "        else:\n",
    "            BH = pd.DataFrame({'none' : []})\n",
    "            return BH\n",
    "            \n",
    "          \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Cutoff function for events with low SNR </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function, may be used to cut-off from the catalogue generation all the events having an SNR ~< 1.\n",
    "This will be done after fitting from a previously generated catalogue the countour line having SNR = 1, the values for the fit function was given by [Mauro Pieroni](https://inspirehep.net/authors/1408985) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate the minimum Chirp Mass giving the redshift in order to obtain a merging event having SNR ~1\n",
    "\n",
    "fit_par = {}\n",
    "\n",
    "fit_par[0] = 1.19731015\n",
    "fit_par[1] = 19.46319054\n",
    "fit_par[2] = 0.60439631\n",
    "\n",
    "def SNR_Cutoff(z):\n",
    "    return (fit_par[0] + fit_par[1]*(z/np.sqrt(0.1))**fit_par[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Parallelized function for the generation of the population </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function, will parallelize the nested cycles splitting that in function of the mass_1 bin, each process will then estimate the number of events for the given mass_1 bin and generate the events to append to the dataframe\n",
    "\n",
    "def init_globals(Nr,Ne,Prc):\n",
    "    global Nreal,Nev,Perc\n",
    "    Nreal = Nr\n",
    "    Nev = Ne\n",
    "    Perc = Prc\n",
    "\n",
    "def  Bin_and_Gen(d,im1) :\n",
    "    # Let's use the fact that the mass probability distribution gives 0 for m2 > m1 \n",
    "    for im2 in (range(im1 + 1)):\n",
    "        for iz in range(len(ran_z) - 1):\n",
    "            for ia_1 in range(len(ran_a_1)-1):\n",
    "                # Let's use the symmetry of the spin amplitude distribution to just run over s_a1 > s_a2, the number of events outside the diagonal should be multiplied by 2\n",
    "                for ia_2 in range(ia_1 + 1):\n",
    "                    for ict1 in range(len(ran_cos_t1)-1):\n",
    "                        # Let's use the symmetry of the spin tilt distribution to just run over s_t1 > s_t2, the number of events outside the diagonal should be multiplied by 2\n",
    "                        for ict2 in range(ict1+1):\n",
    "                            # estimating the value of NDistrib in function of the values, the value will be interpolated with the trapeze method\n",
    "                            \n",
    "                            nstep =  NDistrib(st.mean([ran_z[iz],ran_z[iz + 1]]),st.mean([ran_m1[im1],ran_m1[im1 + 1]]),st.mean([ran_m2[im2],ran_m2[im2 + 1]]),st.mean([ran_a_1[ia_1],ran_a_1[ia_1 + 1]])\\\n",
    "                                     ,st.mean([ran_a_2[ia_2],ran_a_2[ia_2 + 1]]),st.mean([ran_cos_t1[ict1],ran_cos_t1[ict1 + 1]]),st.mean([ran_cos_t2[ict2],ran_cos_t2[ict2 + 1]]))\n",
    "                            # to obtain the real result of the integral, we now need to multiply for the 4 factor due to the used simmetries of spin amplitude and spin tilt distribution, time the values of the delta of all the integration variables  \n",
    "                            \n",
    "                            nstep *= 4.*(ran_z[iz +1] - ran_z[iz])*(ran_m1[im1 + 1] - ran_m1[im1])*(ran_m2[im2 + 1] - ran_m2[im2])*(ran_a_1[ia_1 + 1] - ran_a_1[ia_1])*(ran_a_2[ia_2 + 1] - ran_a_2[ia_2])\\\n",
    "                                     *(ran_cos_t1[ict1+1]-ran_cos_t1[ict1])*(ran_cos_t2[ict2+1]-ran_cos_t2[ict2])\n",
    "                            \n",
    "                            # If we are on the diagonal bin for ia or ict, we don't need to multiply the events by 2 !\n",
    "                            \n",
    "                            if(ia_1 == ia_2) : nstep = nstep / 2.\n",
    "                            if(ict1 == ict2) : nstep = nstep / 2.     \n",
    "                            \n",
    "                            # Addint the fraction of events to the cumulative sum\n",
    "                            \n",
    "                            with Nreal.get_lock():            \n",
    "                                Nreal.value += nstep \n",
    "                            \n",
    "                            # Checking if mode_fast_mc and implementing\n",
    "                                                        \n",
    "                            if(mode_fastmc):\n",
    "                                if(nstep >=1.):\n",
    "                                    if(nstep - round(nstep) >= 0):\n",
    "                                        res = nstep - round(nstep)\n",
    "                                        if(np.random.random() <= res):\n",
    "                                            nstep = round(nstep) + 1.\n",
    "                                    else:\n",
    "                                        res = nstep + 1. - round(nstep)\n",
    "                                        if(np.random.random() >= res):\n",
    "                                            nstep = round(nstep) - 1.\n",
    "                                else:\n",
    "                                        if(np.random.random() <= nstep):\n",
    "                                            nstep = 1.\n",
    "                            \n",
    "                            # Checking if mode exotic\n",
    "                                        \n",
    "                            if(mode_ex):\n",
    "                                nstep += (np.random.random()*0.5)\n",
    "                                \n",
    "                            # The value need to be round up to an integer\n",
    "                            nstep = round(nstep)\n",
    "                                                                                    \n",
    "                            with Nev.get_lock():\n",
    "                                Nev.value += int(nstep)\n",
    "                            \n",
    "                            # The estimated number of events will now be generated, if mode SNR_cut the program will try to generate only if events with SNR bigger than cut are possible\n",
    "                            \n",
    "                            if((not SNR_Cut) or (SNR_Cut and (ChirpMass(ran_m1[im1 +1], ran_m2[im2 +1]) > SNR_Cutoff(ran_z[iz])))):\n",
    "                            \n",
    "                                for i in range(int(nstep)):\n",
    "                                    delta_BH = Gen_Events_Parameters(im1, im2, iz, ia_1, ia_2, ict1, ict2)\n",
    "                                    if(not delta_BH.empty):\n",
    "                                        d.append(delta_BH)\n",
    "\n",
    "    # Increase the percentage index and print percentage\n",
    "    \n",
    "    with Perc.get_lock():\n",
    "         Perc.value += 1\n",
    "         print('Percentage of completition : ',(Perc.value*100.)/(len(ran_m1)-1), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Global Variables of the Simulation </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The global variables of the simulation will be set to :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags for the execution modes, initialized to false, check the the FLAG selection section for additional informations and initializing them !\n",
    "\n",
    "mode_ex = False\n",
    "mode_fastmc = False\n",
    "Red_evol = False\n",
    "SNR_Cut = False\n",
    "sel_rs = False\n",
    "\n",
    "# Number of jobs spawned by the multiprocessing part of the program (use 9/10 * number of core to avoid problems)\n",
    "\n",
    "n_jobs = (mp.cpu_count() - 4)\n",
    "\n",
    "# To avoid to saturate the ram when copying the generated list to a dataframe, the process will be made by slicing the list in percentage\n",
    "\n",
    "cp_perc = 0.1 # If ram > 16 GB put cp_perc = 1 to do the copy in one single step\n",
    "\n",
    "# Merger distribution parameters\n",
    "\n",
    "T_obs = 3. # Lisa estimated years of observation\n",
    "max_tc = 10000. # max years of coalescence time for a BBH mergine event \n",
    "zmax = 2.0 # z value corrispondent to 2 gigaparsec\n",
    "frq_max = 0.5 # Maximum frequency in hertz to which the LISA detector is sensitive \n",
    "\n",
    "#General Constants \n",
    "\n",
    "c = 299792.46 # speed of light in Km/sec\n",
    "G = 6.674*(10.**(-11.)) # Gravitational constant in m^3⋅kg^−1⋅s^−2\n",
    "sol_mass = 1.988e30 # Value of the Solar Mass in Kg\n",
    "H_0 = 67.8 # Hubble constant in Km/(s*MPc)\n",
    "year = 365.25*24*60*60 # Years in second \n",
    "    \n",
    "# Precision settings for the binned variables\n",
    "\n",
    "mass_prec = 75            # Binning density for the masses\n",
    "z_prec = 40             # Binning density for the redshift (affect distance density)\n",
    "spin_ampl_prec = 20       # Binning density for the spin amplitudes\n",
    "spin_tilt_prec = 20      # Binning density for the spin tilt s (setted low as not really needed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Colormaps of the probability functions and check of reliability </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the colormaps of the probability functions to check how they behave :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Colormap of the mass distribution function\n",
    "\n",
    "Z = np.zeros((250,250))\n",
    "ran_m1 = np.linspace(m_min,m_max,250)\n",
    "ran_m2 = np.linspace(m_min,m_max,250)\n",
    "X, Y = np.meshgrid(ran_m1, ran_m2)\n",
    "\n",
    "# Mass distribution model B used for the simulation with the values of arxiv 1811.12940\n",
    "\n",
    "# MassPhaseSpace = ModBPS(ran_m1, ran_m2, m_min, m_max, alpha, beta_q)\n",
    "\n",
    "# Mass distribution model C used for the simulation with the values of arxiv 2010.14533\n",
    "\n",
    "PLPS = PowerLawPS(ran_m1, m_min, m_max, alpha)\n",
    "GSPS = GaussPS(ran_m1, m_min, m_max, mu_m, sigma_m) \n",
    "Mass_PS = ModCPS(ran_m1, ran_m2, m_min, m_max, alpha, beta_q, delta_m, lambda_peak, mu_m, sigma_m, PLPS, GSPS, 1.)\n",
    "\n",
    "print('The integrated probability for all possible mass pairs  before normalization is : ', Mass_PS) \n",
    "\n",
    "for i in range(len(ran_m1) -1):\n",
    "    for j in range(len(ran_m2) - 1):\n",
    "        \n",
    "        # Value of the colormap for the mass distribuction used in arxiv 1811.12940, it is estimated with a trapezoid formula to avoid singularities in the extremes\n",
    "        \n",
    "        # Z[j][i] = MassDistr(0.5*(X[j][i] + X[j][i + 1]), 0.5*(Y[j][i] + Y[j + 1][i]), m_min, m_max, alpha, beta_q, (1./MassPhaseSpace))\n",
    "        \n",
    "        # Value of the colormap for the mass distribuction used in arxiv 2010.14533, it is estimated with a trapezoid formula to avoid singularities in the extremes\n",
    "        \n",
    "        Z[j][i] = MassDistr(0.5*(X[j][i] + X[j][i + 1]), 0.5*(Y[j][i] + Y[j + 1][i]), m_min, m_max, alpha, beta_q, delta_m, lambda_peak, mu_m, sigma_m, PLPS, GSPS, Mass_PS)\n",
    "        \n",
    "        # Fulfill the borders of the colormap by extending the nearest value\n",
    "        \n",
    "        if(i == (len(ran_m1) -2)):\n",
    "            #Z[j][i+1] = MassDistr(0.5*(X[j][i] + X[j][i + 1]), 0.5*(Y[j][i] + Y[j + 1][i]), m_min, m_max, alpha, beta_q, (1./MassPhaseSpace))\n",
    "            Z[j][i+1] = MassDistr(0.5*(X[j][i] + X[j][i + 1]), 0.5*(Y[j][i] + Y[j + 1][i]), m_min, m_max, alpha, beta_q, delta_m, lambda_peak, mu_m, sigma_m, PLPS, GSPS, Mass_PS)\n",
    "        if(j == (len(ran_m2) -2)):\n",
    "            #Z[j+1][i] = MassDistr(0.5*(X[j][i] + X[j][i + 1]), 0.5*(Y[j][i] + Y[j + 1][i]), m_min, m_max, alpha, beta_q, (1./MassPhaseSpace))\n",
    "            Z[j+1][i] = MassDistr(0.5*(X[j][i] + X[j][i + 1]), 0.5*(Y[j][i] + Y[j + 1][i]), m_min, m_max, alpha, beta_q, delta_m, lambda_peak, mu_m, sigma_m, PLPS, GSPS, Mass_PS)\n",
    "        \n",
    "Z[len(ran_m2) - 1][len(ran_m1) -1] = MassDistr(0.5*(X[len(ran_m2) - 1][len(ran_m1) -2] + X[len(ran_m2) - 1][len(ran_m1) -1]), 0.5*(Y[len(ran_m2) - 2][len(ran_m1) - 1] + Y[len(ran_m2) - 1][len(ran_m1) -1]), m_min, m_max, alpha, beta_q, delta_m, lambda_peak, mu_m, sigma_m, PLPS, GSPS, Mass_PS)\n",
    "\n",
    "# Plotting the countour plot\n",
    "\n",
    "plt.contourf(X, Y, Z, 1000, cmap='jet')\n",
    "plt.colorbar();\n",
    "plt.xlabel(r'$m_1$', fontsize = 15)\n",
    "plt.ylabel(r'$m_2$', fontsize = 15)\n",
    "plt.title('Mass Distribution Function', fontsize = 15)\n",
    "plt.loglog()\n",
    "plt.savefig('MassDistrib.png',dpi=500)\n",
    "\n",
    "# Testing also the integrated total probability\n",
    "\n",
    "totprob = ModCPS(ran_m1, ran_m2, m_min, m_max, alpha, beta_q, delta_m, lambda_peak, mu_m, sigma_m, PLPS, GSPS, Mass_PS)\n",
    "\n",
    "\n",
    "\n",
    "print('The integrated probability for all possible mass pairs after normalization is : ', totprob) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colormap of the spin amplitude distribution function, it may be observed the symmetry for swaps among a_1 and a_2\n",
    "\n",
    "Z = np.zeros((250,250))\n",
    "ran_a1 = np.linspace(0.,a_max,250)\n",
    "ran_a2 = np.linspace(0.,a_max,250)\n",
    "BetaVal = Beta_Func(ran_a1, alpha_a, beta_a)\n",
    "X, Y = np.meshgrid(ran_a1, ran_a2)\n",
    "\n",
    "for i in range(len(ran_a1) -1):\n",
    "    for j in range(len(ran_a2) -1):\n",
    "        Z[j][i] = SpinModDistrib(0.5*(X[j][i] + X[j][i + 1]), alpha_a, beta_a, BetaVal)*SpinModDistrib(0.5*(Y[j][i] + Y[j+1][i]), alpha_a, beta_a, BetaVal)\n",
    "        \n",
    "        # Fulfill the borders of the colormap by extending the nearest value\n",
    "        \n",
    "        if(i == (len(ran_a1) -2)):\n",
    "            Z[j][i+1] = SpinModDistrib(0.5*(X[j][i] + X[j][i + 1]), alpha_a, beta_a, BetaVal)*SpinModDistrib(0.5*(Y[j][i] + Y[j+1][i]), alpha_a, beta_a, BetaVal)\n",
    "        if(j == (len(ran_m2) -2)):\n",
    "            Z[j+1][i] = SpinModDistrib(0.5*(X[j][i] + X[j][i + 1]), alpha_a, beta_a, BetaVal)*SpinModDistrib(0.5*(Y[j][i] + Y[j+1][i]), alpha_a, beta_a, BetaVal)\n",
    "        \n",
    "Z[len(ran_a2) - 1][len(ran_a1) -1] = SpinModDistrib(0.5*(X[len(ran_a2) - 1][len(ran_a1)-2] + X[len(ran_a2) - 1][len(ran_a1) -1]), alpha_a, beta_a, BetaVal)*SpinModDistrib(0.5*(Y[len(ran_a2) - 2][len(ran_a1) -1] + Y[len(ran_a2) - 1][len(ran_a1) -1]), alpha_a, beta_a, BetaVal)\n",
    "\n",
    "# Plotting the countour plot\n",
    "        \n",
    "plt.contourf(X, Y, Z, 100, cmap='jet')\n",
    "plt.colorbar();\n",
    "plt.xlabel(r'$a_1$', fontsize = 15)\n",
    "plt.ylabel(r'$a_2$', fontsize = 15)\n",
    "plt.title('Spin Amplitude Distribution Function', fontsize = 15)\n",
    "plt.savefig('SpinAmpDistrib.png',dpi=500)\n",
    "\n",
    "# Testing also the integrated total probability\n",
    "\n",
    "totprob = 0.\n",
    "\n",
    "for i in range(len(ran_a1)-1):\n",
    "    for j in range(len(ran_a2)-1):\n",
    "        totprob += (ran_a1[i + 1] - ran_a1[i])*(ran_a2[j + 1] - ran_a2[j])*SpinModDistrib(st.mean([ran_a1[i],ran_a1[i+1]]), alpha_a, beta_a, BetaVal)*SpinModDistrib(st.mean([ran_a2[j],ran_a2[j+1]]), alpha_a, beta_a, BetaVal)\n",
    "\n",
    "print('The integrated probability for all possible spin amplitudes is : ', totprob)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Colormap of the spin tilt distribution function, it may be observed the symmetry for swap between cos(t1) and cos(t2)\n",
    "\n",
    "Z = np.zeros((250,250))\n",
    "ran_cos_t1 = np.linspace(-1.,1.,250)\n",
    "ran_cos_t2 = np.linspace(-1.,1.,250)\n",
    "X, Y = np.meshgrid(ran_cos_t1, ran_cos_t2)\n",
    "\n",
    "for i in range(len(ran_cos_t1) -1):\n",
    "    for j in range(len(ran_cos_t2) -1):\n",
    "        \n",
    "        Z[j][i] = SpinOrientDistrib(0.5*(X[j][i] + X[j][i + 1]), 0.5*(Y[j][i] + Y[j+1][i]), zeta, sigma_1, sigma_2)\n",
    "        \n",
    "        # Fulfill the borders of the colormap by extending the nearest value\n",
    "        \n",
    "        if(i == (len(ran_cos_t1) -2)):\n",
    "            Z[j][i+1] = SpinOrientDistrib(0.5*(X[j][i] + X[j][i + 1]), 0.5*(Y[j][i] + Y[j+1][i]), zeta, sigma_1, sigma_2)\n",
    "        if(j == (len(ran_cos_t2) -2)):\n",
    "            Z[j+1][i] = SpinOrientDistrib(0.5*(X[j][i] + X[j][i + 1]), 0.5*(Y[j][i] + Y[j+1][i]), zeta, sigma_1, sigma_2)\n",
    "        \n",
    "Z[len(ran_cos_t2) - 1][len(ran_cos_t1) -1] = SpinOrientDistrib(0.5*(X[len(ran_cos_t2) - 1][len(ran_cos_t1) -2] + X[len(ran_cos_t2) - 1][len(ran_cos_t1) -1]), 0.5*(Y[len(ran_cos_t2) - 2][len(ran_cos_t1) -1] + Y[len(ran_cos_t2) - 1][len(ran_cos_t1) -1]), zeta, sigma_1, sigma_2)\n",
    "\n",
    "# Plotting the countour plot\n",
    "\n",
    "plt.contourf(X, Y, Z, 100, cmap='jet')\n",
    "plt.colorbar();\n",
    "plt.xlabel(r'$cos(t_1)$', fontsize = 15)\n",
    "plt.ylabel(r'$cos(t_2)$', fontsize = 15)\n",
    "plt.title('Spin tilt angles Distribution function', fontsize = 15)\n",
    "plt.savefig('SpinTiltDistrib.png',dpi=500)\n",
    "\n",
    "# Testing also the integrated total probability\n",
    "\n",
    "totprob = 0.\n",
    "\n",
    "for i in range(len(ran_cos_t1)-1):\n",
    "    for j in range(len(ran_cos_t2)-1):\n",
    "        totprob += (ran_cos_t1[i + 1] - ran_cos_t1[i])*(ran_cos_t2[j + 1] - ran_cos_t2[j])*SpinOrientDistrib(st.mean([ran_cos_t1[i],ran_cos_t1[i + 1]]), st.mean([ran_cos_t2[j],ran_cos_t2[j + 1]]), zeta, sigma_1, sigma_2)\n",
    "\n",
    "print('The integrated probability for all possible tilt angles is : ', totprob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reset the predefined array to avoid RAM consumption :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, Z = np.zeros(1),np.zeros(1),np.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Setting of the analyzed phase space </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation will be spanned over the following range of variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the mass phase space\n",
    "\n",
    "ran_m1 = np.linspace(m_min,m_max,mass_prec)\n",
    "ran_m2 = np.linspace(m_min,m_max,mass_prec)\n",
    "PL_norm = PowerLawPS(ran_m1, m_min, m_max, alpha)\n",
    "GS_norm = GaussPS(ran_m1, m_min, m_max, mu_m, sigma_m) \n",
    "Mass_PS = ModCPS(ran_m1, ran_m2, m_min, m_max, alpha, beta_q, delta_m, lambda_peak, mu_m, sigma_m, PLPS, GSPS, 1.)\n",
    "\n",
    "# Initialization of the distance phase space\n",
    "\n",
    "ran_z = np.linspace(0.,zmax, z_prec)    # Don't put bins too small or the volume wouldn't be enough to generate events\n",
    "\n",
    "# Initialization of the spin amplitude phase space\n",
    "\n",
    "ran_a_1 = np.linspace(0., a_max,spin_ampl_prec)\n",
    "ran_a_2 = np.linspace(0., a_max,spin_ampl_prec)\n",
    "BetaVal = Beta_Func(ran_a_1, alpha_a, beta_a)\n",
    "\n",
    "# Initialization of the spin tilt phase space\n",
    "\n",
    "ran_cos_t1 = np.linspace(-1.,1.,spin_tilt_prec)\n",
    "ran_cos_t2 = np.linspace(-1.,1.,spin_tilt_prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the result will be saved in the BHCat dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BHCat = pd.DataFrame(columns=['Redshift', 'Mass1', 'Mass2', 'InitialFrequency', 'InBandTime', 'EclipticLongitude', 'EclipticLatitude', 'Inclination', 'Polarization', 'InitialPhase', 'CoalTime', 'Distance', 'Spin1', 'Spin2', 'AzimuthalAngleOfSpin1', 'AzimuthalAngleOfSpin2'])\n",
    "\n",
    "# The Lisa Dataframe instead will be saved without the EventName and will have the following variables and unit of measure \n",
    "\n",
    "SOBBHsunits = {\n",
    "\n",
    "'Redshift': 'Unit',\\\n",
    "    \n",
    "'Mass1': 'SolarMass',\\\n",
    "    \n",
    "'Mass2': 'SolarMass',\\\n",
    "\n",
    "'InitialFrequency' : 'Hertz',\\\n",
    "    \n",
    "'InBandTime' : 'Years',\\\n",
    "\n",
    "'EclipticLongitude' : 'Radian',\\\n",
    "    \n",
    "'EclipticLatitude' : 'Radian',\\\n",
    "    \n",
    "'Inclination' : 'Radian',\\\n",
    "\n",
    "'Polarization' : 'Radian',\\\n",
    "    \n",
    "'InitialPhase' : 'Radian',\\\n",
    "    \n",
    "'CoalTime' : 'Years',\\\n",
    "    \n",
    "'Distance' : 'GigaParsec',\\\n",
    "\n",
    "'Spin1' : 'Unit',\\\n",
    "    \n",
    "'Spin2' : 'Unit',\\\n",
    "    \n",
    "'AzimuthalAngleOfSpin1' : 'Radian',\\\n",
    "    \n",
    "'AzimuthalAngleOfSpin2' : 'Radian'    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the format of an added merging event\n",
    "#BH= pd.DataFrame([[0.2,2 4.6, 18.3, 0.2, 128.5, -0.9, 4.25, 2.4, 1.6, 5.2, 251., 0.8, 0.2, 0.15, -0.2,0.4],], columns=['EventName', 'Redshift', 'Mass1', 'Mass2', 'InitialFrequency', 'EclipticLongitude', 'EclipticLatitude', 'Inclination', 'Polarization', 'InitialPhase', 'CoalTime', 'Distance', 'Spin1', 'Spin2', 'AzimuthalAngleOfSpin1', 'AzimuthalAngleOfSpin2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> FLAG selection section </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard way of simulating the events will generate the same number of events in the same range of variables every time it was run...\n",
    "To give to the simulation a little bit of randomness, and allow the generation of merging events with exotic range of variable, set the **exotic_mode** flags to true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode_ex = True # If true, in each volume of the phase space it will randomly add a number between [0,0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In alternative, the events may be simulated using a fast Monte Carlo method, to do so set the **mode_fastmc** flag to true.\\\n",
    "**Beware, only one mode flag may be setup at a single time !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_fastmc = True # If True, on each bin will generate a random uniform value and if the value is within the probability range a new event will be added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also decide to simulate the catalogue with a redshift evolving merging rate, by setting to true the Red_evol flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Red_evol = True # If true, the merging rate will evolve as a function of redshift, if false it will be assumed constant over the volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we may set the flag SNR_Cut if we wish to simulate only events with chirpmass bigger than the value defined by the SNR_Cutoff function, this will only generate events with SNR bigger then the imposed treshold value :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_Cut = True # If true only events resulting in an SNR bigger than the imposed cutoff would appear in the final catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, you may choose to manually set up the random seeds for the simulation, in order to make that more reproducible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sel_rs = True # Uncomment this to manually select the random seed of the simulation\n",
    "\n",
    "if(sel_rs):\n",
    "    np_seed = 0 # Change this value to the desired seed for numpy\n",
    "    rd_seed = 0 # Change this value to the desired seed for random\n",
    "    np.random.seed(np_seed)\n",
    "    random.seed(rd_seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Main body of the simulation </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may finally launch the pipeline to generate the merging events in the considered volume :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The total time used to generate the merging events by multipling for the rate of merging will be set to max_tc\n",
    "T_tot = max_tc\n",
    "\n",
    "# Checking if flags variable are correct\n",
    "\n",
    "if(mode_fastmc and mode_ex):\n",
    "    print('!! WARNING !! The simulation is not able to run with both mode flags on, it will be setted by default to mode_fastmc !')\n",
    "    mode_ex = False\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':                                    \n",
    "    # start the worker processes equals to n_jobs\n",
    "    print('Percentage of completition : ',0., ' %')\n",
    "    Nev = Value('i', 0)\n",
    "    Perc = Value('i', 0)\n",
    "    Nreal = Value('d', 0.)\n",
    "    with Pool(processes = n_jobs, initializer = init_globals, initargs = (Nreal,Nev, Perc)) as pool:\n",
    "        manager = Manager()\n",
    "        d = manager.list() \n",
    "        par_func = partial(Bin_and_Gen, d)\n",
    "        pool.map(par_func, range(len(ran_m1)-1))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "                                                       \n",
    "print('During the simulation, ', Nev.value, ' merging events where generated over the ',int(round(Nreal.value)), ' predicted !')\n",
    "if(SNR_Cut):\n",
    "    print('Among the ', Nev.value, ' merging events generated ',Nev.value - len(d),' of the generated events were rejected for low SNR or frequency outisde of the Lisa band')\n",
    "else:\n",
    "    print('Among the ', Nev.value, ' merging events generated ',Nev.value - len(d),' of the generated events were rejected as outisde of the Lisa band')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may now save the generated list to a dataframe and reset the value of said list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print ('The generated list will now be copied to a dataframe !')\n",
    "Perc.value = 0\n",
    "while (len(d) > 0):\n",
    "    slc_end = int((cp_perc*Nev.value)+1)\n",
    "    delta_BH = pd.concat(d[0:slc_end], ignore_index=True)\n",
    "    del d[0:slc_end]\n",
    "    BHCat = BHCat.append(delta_BH, sort= False, ignore_index = True)\n",
    "    Perc.value += 1\n",
    "    print('Percentage of copying : ',(Perc.value*cp_perc*100),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and add to the generated dataframe all the missing uniform variables by using fast vectorized operations :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BHCat['Distance'] = Z_to_Gpc(BHCat.Redshift)                                # Estimate the distance from the redshift using Hubble Law\n",
    "BHCat['InitialPhase'] = np.random.rand(len(BHCat.Mass1))*2.*np.pi           # Random value between 0 and 2pi\n",
    "BHCat['EclipticLongitude'] = (np.random.rand(len(BHCat.Mass1))-0.5)*np.pi   # Random value between -pi/2 and pi/2\n",
    "BHCat['EclipticLatitude'] = np.random.rand(len(BHCat.Mass1))*2.*np.pi       # Random value between 0 and 2pi\n",
    "BHCat['Inclination'] = np.random.rand(len(BHCat.Mass1))*np.pi               # Random value between 0 and pi\n",
    "BHCat['Polarization'] = np.random.rand(len(BHCat.Mass1))*2.*np.pi           # Random value between 0 and 2pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we may finally save the complete dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Dataframe\n",
    "\n",
    "df_key = 'SOBBH'\n",
    "\n",
    "if(mode_ex):\n",
    "    df_nm = 'SOBBHCatalogueExotic.h5'        \n",
    "else:\n",
    "    if(mode_fastmc):\n",
    "        df_nm = 'SOBBHCatalogueMC.h5'       \n",
    "    else:\n",
    "        df_nm = 'SOBBHCatalogue.h5'\n",
    "        \n",
    "BHCat.to_hdf(df_nm, df_key, mode='w')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataframe and sort by frequency to see over which values the frequencies spanned :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BHCat = pd.read_hdf(df_nm, df_key)\n",
    "BHCat.sort_values(by=['InitialFrequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that the generated dataframe is following the density distributions, let's plot a scatter plot of the masses :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(BHCat['Mass1'], BHCat['Mass2'], s=2)\n",
    "plt.xlabel('Mass 1 [Solar Mass]', fontsize = 15)\n",
    "plt.ylabel('Mass 2 [Solar Mass]', fontsize = 15)\n",
    "plt.savefig('MassesScatterplot.png',dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together with a scatter plot for the spin amplitude and orientation :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(BHCat['Spin1'], BHCat['Spin2'], s=2)\n",
    "plt.xlabel('Firts spin amplitude a1', fontsize = 15)\n",
    "plt.ylabel('Second spin amplitude a2', fontsize = 15)\n",
    "plt.savefig('FrqHist.png',dpi=500)\n",
    "plt.savefig('SpinAmplitudesScatterplot.png',dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(BHCat['AzimuthalAngleOfSpin1'], BHCat['AzimuthalAngleOfSpin2'], s=2)\n",
    "plt.xlabel('Firts spin orientation angle [rad]', fontsize = 15)\n",
    "plt.ylabel('Second spin orientation angle [rad]', fontsize = 15)\n",
    "plt.xlim(0,np.pi)\n",
    "plt.ylim(0,np.pi)\n",
    "plt.savefig('SpinTiltsScatterplot.png',dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the properties of the generated dataframe may be observed from an histogram of the frequencies :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "log_bin = np.logspace(-4,0,1000)\n",
    "plt.hist(BHCat['InitialFrequency'], bins = log_bin, label = 'Occurrencies per Bin')\n",
    "plt.xlabel('Frequency [Hz]', fontsize = 15)\n",
    "plt.xlim(10**(-4),1)\n",
    "plt.axvspan(frq_max-0.001, frq_max + 0.001, 0, 1, color = 'black', label = 'LISA sensitivity cutoff')\n",
    "plt.legend(loc = 1)\n",
    "plt.ylabel('Number of occurrencies', fontsize = 15)\n",
    "plt.savefig('FrqHist.png',dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and an hystogram showing the time of each event inside the LISA band :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "log_bin = np.logspace(-4,3,1000)\n",
    "plt.hist(BHCat['InBandTime'], bins = log_bin, label = 'Occurrencies per Bin')\n",
    "plt.xlabel('Residual time in LISA frequency band [years]', fontsize = 15 )\n",
    "plt.axvspan(T_obs - 0.01, T_obs + 0.01, 0, 1, color = 'black', label = 'LISA mission time')\n",
    "plt.legend(loc = 1)\n",
    "plt.ylabel('Number of occurrencies', fontsize = 15)\n",
    "plt.savefig('TimeInFrequencyBand.png',dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's convert the dataframe to the standard LISA type dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LH = LISAhdf5('LISA'+df_nm)\n",
    "pr = ParsUnits()\n",
    "\n",
    "for p in list(SOBBHsunits.keys()):\n",
    "    pr.addPar(p,BHCat[p],SOBBHsunits[p])\n",
    "\n",
    "pr.addPar(\"SourceType\",df_key, \"name\")    \n",
    "LH.addSource('SOBBH',pr, overwrite=True)   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
